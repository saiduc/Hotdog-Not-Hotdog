#+TITLE: Hotdog or Not Hotdgog Classifier
#+AUTHOR: Sai Pandian

* Loading the Images

#+begin_src jupyter-python
import torch
import torchvision
import torchvision.transforms as transforms
#+end_src

#+RESULTS:

#+begin_src jupyter-python
# Normalise all the images
transform = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])

# Load the images into train and test sets
trainset = torchvision.datasets.ImageFolder('./data/train', transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)

testset = torchvision.datasets.ImageFolder('./data/test', transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)

# The two possible labels
classes = ('hotdog', 'nothotdog')
#+end_src

#+RESULTS:

* Displaying the Images

#+begin_src jupyter-python
import matplotlib.pyplot as plt
import numpy as np
import matplotlib

%matplotlib inline
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def imshow(img):
    img = img / 2 + 0.5
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

dataiter = iter(trainloader)
images, labels = dataiter.next()

imshow(torchvision.utils.make_grid(images))

print(' '.join('%5s' % classes[label] for label in labels))
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/fe86313d5f0dddcf88161a12e7b37610f1f77a70.png]]
: nothotdog hotdog hotdog nothotdog
:END:

* Constructing the CNN

#+begin_src jupyter-python
import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 2)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
        
net = Net()
#+end_src

#+RESULTS:

* Training the Network

#+begin_src jupyter-python
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from time import time

epochs = 60
time0 = time()

for epoch in range(epochs):
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs
        inputs, labels = data
        
        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        
    print("Epoch {} - Training loss: {}".format(epoch, running_loss/len(trainloader)))
 
print("Training Time (in minutes): ", (time() - time0)/60)
#+end_src

#+RESULTS:
#+begin_example
Epoch 0 - Training loss: 0.692146941781044
Epoch 1 - Training loss: 0.5975853744447231
Epoch 2 - Training loss: 0.3894248715955764
Epoch 3 - Training loss: 0.3689977326244116
Epoch 4 - Training loss: 0.36445348809286954
Epoch 5 - Training loss: 0.3562614530660212
Epoch 6 - Training loss: 0.3408904492352158
Epoch 7 - Training loss: 0.33603353391215207
Epoch 8 - Training loss: 0.3306163412909955
Epoch 9 - Training loss: 0.32497734621539714
Epoch 10 - Training loss: 0.31833813995681703
Epoch 11 - Training loss: 0.30901647106930613
Epoch 12 - Training loss: 0.30397088106907905
Epoch 13 - Training loss: 0.29670102179585955
Epoch 14 - Training loss: 0.2854843460023403
Epoch 15 - Training loss: 0.28574398887599817
Epoch 16 - Training loss: 0.2730287608825602
Epoch 17 - Training loss: 0.2593679716628976
Epoch 18 - Training loss: 0.2612276639981428
Epoch 19 - Training loss: 0.2442739779469557
Epoch 20 - Training loss: 0.2352324973382056
Epoch 21 - Training loss: 0.21958030147757382
Epoch 22 - Training loss: 0.20739688958297484
Epoch 23 - Training loss: 0.19739163122768513
Epoch 24 - Training loss: 0.17649399203645588
Epoch 25 - Training loss: 0.1775827807809801
Epoch 26 - Training loss: 0.14854292412586437
Epoch 27 - Training loss: 0.14070111560585793
Epoch 28 - Training loss: 0.1270828691312927
Epoch 29 - Training loss: 0.10869616680385662
Epoch 30 - Training loss: 0.10382226903274204
Epoch 31 - Training loss: 0.08021166541138496
Epoch 32 - Training loss: 0.071283855145551
Epoch 33 - Training loss: 0.08299209648869874
Epoch 34 - Training loss: 0.0708345082733813
Epoch 35 - Training loss: 0.065133224152977
Epoch 36 - Training loss: 0.09650077689318413
Epoch 37 - Training loss: 0.03258347664705696
Epoch 38 - Training loss: 0.01595526158778949
Epoch 39 - Training loss: 0.012660474024346993
Epoch 40 - Training loss: 0.07001286516766773
Epoch 41 - Training loss: 0.03546076242378237
Epoch 42 - Training loss: 0.010758275786356443
Epoch 43 - Training loss: 0.004370543150951189
Epoch 44 - Training loss: 0.0021981906740509024
Epoch 45 - Training loss: 0.0016490788284711257
Epoch 46 - Training loss: 0.0014208523201420177
Epoch 47 - Training loss: 0.0011306588264904747
Epoch 48 - Training loss: 0.0008763636951666243
Epoch 49 - Training loss: 0.0007537993130886384
Epoch 50 - Training loss: 0.0006657075347596652
Epoch 51 - Training loss: 0.000588798365855606
Epoch 52 - Training loss: 0.0005242336197515449
Epoch 53 - Training loss: 0.0004879535687477876
Epoch 54 - Training loss: 0.00044403717093153004
Epoch 55 - Training loss: 0.00041151628843395116
Epoch 56 - Training loss: 0.0003752741753043267
Epoch 57 - Training loss: 0.0003520078512537701
Epoch 58 - Training loss: 0.0003268077924720068
Epoch 59 - Training loss: 0.00030383143924737866
Training Time (in minutes):  7.782852784792582
#+end_example

#+begin_src jupyter-python
PATH = './hotdog.pth'
torch.save(net.state_dict(), PATH)
#+end_src

#+RESULTS:

* Testing the Model

#+begin_src jupyter-python
dataiter = iter(testloader)
images, labels = dataiter.next()

# print images
imshow(torchvision.utils.make_grid(images))
print("Ground Truth: ", " ".join('%5s' % classes[label] for label in labels))

outputs = net(images)

_, predicted = torch.max(outputs, 1)
print("Predicted: ", " ".join("%5s" % classes[predict] for predict in predicted))
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/cdb348c8035b7d50e766ca66a065a9b75c1f502e.png]]
: Ground Truth:  nothotdog nothotdog hotdog nothotdog
: Predicted:  nothotdog hotdog hotdog nothotdog
:END:
#+RESULTS:

#+begin_src jupyter-python
correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the test images: %d %%' % (
    100 * correct / total))
#+end_src

#+RESULTS:
: Accuracy of the network on the test images: 84 %
