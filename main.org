#+TITLE: Hotdog or Not Hotdgog Classifier
#+AUTHOR: Sai Pandian

#+begin_src jupyter-python
import torch
import torchvision
import torchvision.transforms as transforms
#+end_src

#+RESULTS:

#+begin_src jupyter-python
# transform = transforms.Compose([transforms.Grayscale(), transforms.Resize((256,256)), transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])

transform = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])

trainset = torchvision.datasets.ImageFolder('./data/train', transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)

testset = torchvision.datasets.ImageFolder('./data/test', transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)

classes = ('hotdog', 'nothotdog')
#+end_src

#+RESULTS:

#+begin_src jupyter-python
import matplotlib.pyplot as plt
import numpy as np
import matplotlib

%matplotlib inline
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def imshow(img):
    img = img / 2 + 0.5
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

dataiter = iter(trainloader)
images, labels = dataiter.next()

imshow(torchvision.utils.make_grid(images))

print(' '.join('%5s' % classes[label] for label in labels))
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/aba16634054ac00b5bec91afe83bd6b82cd3fe88.png]]
: hotdog hotdog nothotdog hotdog
:END:

#+begin_src jupyter-python
import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 2)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
        
net = Net()
#+end_src

#+RESULTS:


#+begin_src jupyter-python
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
from time import time

epochs = 60
time0 = time()

for epoch in range(epochs):
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs
        inputs, labels = data
        
        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        
    print("Epoch {} - Training loss: {}".format(epoch, running_loss/len(trainloader)))
 
print("Training Time (in minutes): ", (time() - time0)/60)
#+end_src

#+RESULTS:
#+begin_example
Epoch 0 - Training loss: 0.6891303879022598
Epoch 1 - Training loss: 0.4958014388158917
Epoch 2 - Training loss: 0.38367323123291136
Epoch 3 - Training loss: 0.35710381137020886
Epoch 4 - Training loss: 0.35499077584967015
Epoch 5 - Training loss: 0.3432975183231756
Epoch 6 - Training loss: 0.3445826208572835
Epoch 7 - Training loss: 0.32611713295616207
Epoch 8 - Training loss: 0.31826693373918535
Epoch 9 - Training loss: 0.3176873366367072
Epoch 10 - Training loss: 0.30485070737823844
Epoch 11 - Training loss: 0.31121890746243297
Epoch 12 - Training loss: 0.2978232608921826
Epoch 13 - Training loss: 0.28892623536568135
Epoch 14 - Training loss: 0.2886886499952525
Epoch 15 - Training loss: 0.2815768826217391
Epoch 16 - Training loss: 0.2706241317540407
Epoch 17 - Training loss: 0.2605920001303311
Epoch 18 - Training loss: 0.2630674726786092
Epoch 19 - Training loss: 0.24742428154265508
Epoch 20 - Training loss: 0.23193477911688387
Epoch 21 - Training loss: 0.22876356543274595
Epoch 22 - Training loss: 0.2118925255620852
Epoch 23 - Training loss: 0.2032882110599894
Epoch 24 - Training loss: 0.1950630684305215
Epoch 25 - Training loss: 0.17982886331202463
Epoch 26 - Training loss: 0.15334563939616783
Epoch 27 - Training loss: 0.14818666929518803
Epoch 28 - Training loss: 0.13317935719778143
Epoch 29 - Training loss: 0.1187522615242051
Epoch 30 - Training loss: 0.11655446089566976
Epoch 31 - Training loss: 0.0937522631965403
Epoch 32 - Training loss: 0.08236905720246068
Epoch 33 - Training loss: 0.0824356260180939
Epoch 34 - Training loss: 0.07326421567151829
Epoch 35 - Training loss: 0.06051615313446757
Epoch 36 - Training loss: 0.04890905878281066
Epoch 37 - Training loss: 0.07628622982177659
Epoch 38 - Training loss: 0.04677424612538692
Epoch 39 - Training loss: 0.05518863168760663
Epoch 40 - Training loss: 0.039343976355162055
Epoch 41 - Training loss: 0.04132721274765504
Epoch 42 - Training loss: 0.02465473025580695
Epoch 43 - Training loss: 0.01980973429307599
Epoch 44 - Training loss: 0.039781174505539585
Epoch 45 - Training loss: 0.020007426820859733
Epoch 46 - Training loss: 0.006272731211805106
Epoch 47 - Training loss: 0.004001743195644977
Epoch 48 - Training loss: 0.0025287907031006007
Epoch 49 - Training loss: 0.0016987019783264864
Epoch 50 - Training loss: 0.0010774204593065554
Epoch 51 - Training loss: 0.0008888770129559588
Epoch 52 - Training loss: 0.0007552271092066398
Epoch 53 - Training loss: 0.000661456043559717
Epoch 54 - Training loss: 0.0005909474059926581
Epoch 55 - Training loss: 0.0005299136888831164
Epoch 56 - Training loss: 0.0004829308309747411
Epoch 57 - Training loss: 0.000446382146914523
Epoch 58 - Training loss: 0.00041005922425572906
Epoch 59 - Training loss: 0.0003798346463542437
Training Time (in minutes):  6.1414554158846535
#+end_example

#+begin_src jupyter-python
PATH = './hotdog.pth'
torch.save(net.state_dict(), PATH)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
dataiter = iter(testloader)
images, labels = dataiter.next()

# print images
imshow(torchvision.utils.make_grid(images))
print("Ground Truth: ", " ".join('%5s' % classes[label] for label in labels))

outputs = net(images)

_, predicted = torch.max(outputs, 1)
print("Predicted: ", " ".join("%5s" % classes[predict] for predict in predicted))
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
ERROR:root:Internal Python error in the inspect module.
Below is the traceback from this internal error.

Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x119b95310>
Traceback (most recent call last):
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 961, in __del__
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 917, in _shutdown_workers
AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_shutdown'
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x119b95310>
Traceback (most recent call last):
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 961, in __del__
    self._shutdown_workers()
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 917, in _shutdown_workers
    if not self._shutdown:
AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_shutdown'
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x119b95310>
Traceback (most recent call last):
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 961, in __del__
    self._shutdown_workers()
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 917, in _shutdown_workers
    if not self._shutdown:
AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_shutdown'
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x119b95310>
Traceback (most recent call last):
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 961, in __del__
    self._shutdown_workers()
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 917, in _shutdown_workers
    if not self._shutdown:
AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_shutdown'
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x119b95310>
Traceback (most recent call last):
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 961, in __del__
    self._shutdown_workers()
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 917, in _shutdown_workers
    if not self._shutdown:
AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_shutdown'
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x119b95310>
Traceback (most recent call last):
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 961, in __del__
    self._shutdown_workers()
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 917, in _shutdown_workers
    if not self._shutdown:
AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_shutdown'
Traceback (most recent call last):
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-29-0748543053c8>", line 1, in <module>
    dataiter = iter(testloader)
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 279, in __iter__
    return _MultiProcessingDataLoaderIter(self)
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 684, in __init__
    self._worker_result_queue = multiprocessing_context.Queue()
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/multiprocessing/context.py", line 103, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/multiprocessing/queues.py", line 41, in __init__
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/multiprocessing/connection.py", line 527, in Pipe
OSError: [Errno 24] Too many open files

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/interactiveshell.py", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'OSError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py", line 1148, in get_records
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py", line 316, in wrapped
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/site-packages/IPython/core/ultratb.py", line 350, in _fixed_getinnerframes
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/inspect.py", line 1503, in getinnerframes
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/inspect.py", line 1461, in getframeinfo
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/inspect.py", line 708, in getsourcefile
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/inspect.py", line 737, in getmodule
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/inspect.py", line 721, in getabsfile
  File "/Users/saipandian/miniconda3/envs/deeplearning/lib/python3.8/posixpath.py", line 379, in abspath
OSError: [Errno 24] Too many open files
#+end_example
# [goto error]
:END:
#+RESULTS:

#+begin_src jupyter-python
correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the test images: %d %%' % (
    100 * correct / total))
#+end_src
